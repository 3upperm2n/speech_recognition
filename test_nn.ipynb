{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Isolated Word Recognition using Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "import numpy as np\n",
    "import sys\n",
    "import tflearn\n",
    "\n",
    "# extract audio features\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### find out the input wav info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samplerate : 8000\n",
      "Bits per sample: 16, Max Amptitude : 32768.0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# check input wavefile format\n",
    "#\n",
    "# https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.io.wavfile.write.html\n",
    "[samplerate, x] = read(\"./datasets/fruits/apple/apple01.wav\")\n",
    "\n",
    "print('samplerate : {}'.format(samplerate))\n",
    "\n",
    "bits_per_sample = None\n",
    "if x.dtype == 'int16':\n",
    "    bits_per_sample = 16\n",
    "elif x.dtype == 'int32':\n",
    "    bits_per_sample = 32\n",
    "elif x.dtype == 'uint8':\n",
    "    bits_per_sample = 8\n",
    "else:\n",
    "    sys.exit(\"unknow wav datatype\")\n",
    "\n",
    "maxAmptitude = float(2 ** (bits_per_sample - 1))\n",
    "\n",
    "print('Bits per sample: {}, Max Amptitude : {}'.format(bits_per_sample, maxAmptitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kiwi': 2, 'apple': 0, 'peach': 5, 'pineapple': 6, 'orange': 4, 'banana': 1, 'lime': 3}\n"
     ]
    }
   ],
   "source": [
    "word_list = ['apple', 'banana', 'kiwi', 'lime', 'orange', 'peach', 'pineapple']\n",
    "word2vec_dd = {}\n",
    "for label, word in enumerate(word_list):\n",
    "    word2vec_dd[word] = label\n",
    "\n",
    "totalwords = len(word_list)\n",
    "\n",
    "print(word2vec_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 98 speech samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples_per_word = 14\n",
    "samples_total = samples_per_word * len(word_list)\n",
    "print(\"There are total {} speech samples.\\n\".format(samples_total))\n",
    "\n",
    "inputaudio_dd = {}\n",
    "\n",
    "targetFolder = './datasets/fruits'\n",
    "for word in word_list:\n",
    "    for sid in range(1,samples_per_word+1): # start from 1\n",
    "        myid = str(sid)\n",
    "        if sid < 10: myid = '0' + str(sid)   # pad zero for numbers < 10\n",
    "        targetWavFile = targetFolder + '/' + word + '/' + word + myid + '.wav'\n",
    "        input_audio = read(targetWavFile)\n",
    "        input_audio = np.array(input_audio[1],dtype=float)\n",
    "        input_audio = input_audio / maxAmptitude  # scale the input using maxAmptitude        \n",
    "        wordtag = word + myid\n",
    "        inputaudio_dd[wordtag] = input_audio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### truncate the input signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated signal length : 2694\n",
      "Each signal is represented by 429 features.\n"
     ]
    }
   ],
   "source": [
    "LARGELEN = 1e10\n",
    "truncate_len = LARGELEN\n",
    "for _, sig in inputaudio_dd.items():\n",
    "    if len(sig) < truncate_len:  truncate_len = len(sig)\n",
    "\n",
    "print('Truncated signal length : {}'.format(truncate_len))\n",
    "\n",
    "#\n",
    "# truncate with min length of the input signal\n",
    "#\n",
    "for name, sig in inputaudio_dd.items():\n",
    "    trunc_sig = sig[:truncate_len]\n",
    "    #\n",
    "    # extract mfcc\n",
    "    #\n",
    "    mfcc_feat = mfcc(trunc_sig,samplerate) \n",
    "    mfcc_feat = mfcc_feat.flatten('C')  # flattern the 33x13 to 1D array(429)\n",
    "    inputaudio_dd[name] = mfcc_feat\n",
    "    \n",
    "## check\n",
    "featDim = len(inputaudio_dd['kiwi11'])\n",
    "print('Each signal is represented by {} features.'.format(featDim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# convert data input numpy array\n",
    "# \n",
    "data = np.zeros((samples_total, featDim))\n",
    "label = np.zeros(samples_total, dtype = np.int)\n",
    "\n",
    "# print data.shape\n",
    "# print label.shape\n",
    "\n",
    "index = 0\n",
    "for key, value in inputaudio_dd.items():\n",
    "    fruitname = str(key)[:-2]\n",
    "    tagid = word2vec_dd[fruitname]\n",
    "    #print fruitname + str(tagid)\n",
    "    data[index,:] = value\n",
    "    #print value\n",
    "    label[index] = int(tagid)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 429)\n",
      "(98,)\n",
      "[2 2 2 2 2 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(label.shape)\n",
    "print(label[:10])\n",
    "# print min(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### split data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 78 out of 98 for training\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# shuffle data sets\n",
    "# note: apply K-fold\n",
    "#\n",
    "total_samples = data.shape[0]\n",
    "indices = np.random.permutation(total_samples)\n",
    "frac = 0.8\n",
    "train_samples = int(round(total_samples * frac))\n",
    "print('Use {} out of {} for training'.format(train_samples, total_samples))\n",
    "\n",
    "training_idx, test_idx = indices[:train_samples], indices[train_samples:]\n",
    "# print test_idx\n",
    "# print label[test_idx]\n",
    "\n",
    "# notes: add validation set\n",
    "x_train, x_test = data[training_idx,:], data[test_idx,:]\n",
    "y_train, y_test = label[training_idx], label[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5 1 3 1 0 2 4 0 4 1 5 6 5 0 4 4 4 2 2]\n",
      "<type 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "# print(x_test)\n",
    "print(y_test)\n",
    "print type(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### one hot encoding on the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(x, n_classes):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "     \"\"\"\n",
    "    return np.eye(n_classes)[x]\n",
    "\n",
    "y_train = one_hot_encode(y_train, totalwords)\n",
    "y_test = one_hot_encode(y_test, totalwords)\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# [2] https://github.com/tflearn/tflearn/blob/master/examples/images/convnet_mnist.py\n",
    "# val_acc: 0.0500\n",
    "net = tflearn.input_data(shape=[None, featDim])\n",
    "net = tflearn.fully_connected(net, 64, \n",
    "                                 activation='relu',\n",
    "                                 regularizer='L2', \n",
    "                                 weight_decay=0.001)\n",
    "net = tflearn.dropout(net, 0.8)\n",
    "\n",
    "net = tflearn.fully_connected(net, 64, \n",
    "                                activation='relu',\n",
    "                                regularizer='L2', \n",
    "                                weight_decay=0.001)\n",
    "net = tflearn.dropout(net, 0.8)\n",
    "\n",
    "net = tflearn.fully_connected(net, totalwords, \n",
    "                                  activation='softmax')\n",
    "\n",
    "sgd = tflearn.SGD(learning_rate=0.1, lr_decay=0.96, decay_step=1000)\n",
    "top_k = tflearn.metrics.Top_k(k=1)\n",
    "net = tflearn.regression(net, optimizer=sgd, metric=top_k,\n",
    "                         loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m1.24264\u001b[0m\u001b[0m | time: 0.001s\n",
      "| SGD | epoch: 050 | loss: 1.24264 - top1: 0.8658 -- iter: 64/78\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m1.67711\u001b[0m\u001b[0m | time: 1.004s\n",
      "| SGD | epoch: 050 | loss: 1.67711 - top1: 0.8149 | val_loss: 0.08835 - val_acc: 1.0000 -- iter: 78/78\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(x_train, y_train, \n",
    "          n_epoch=50, \n",
    "          validation_set=(x_test, y_test),\n",
    "          show_metric=True, run_id=\"dense_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:speech_dpl]",
   "language": "python",
   "name": "conda-env-speech_dpl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
